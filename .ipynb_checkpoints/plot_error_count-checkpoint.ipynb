{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68092868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from utils.registry import registry, setup_imports\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86879409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer_heanet_mtl import validate_model, evaluate, load_mp_data\n",
    "from trainer_heanet_mtl_HEA import load_hea_data, load_hea_data_single_file\n",
    "from datasets.Mp_dataset import MpGeometricDataset\n",
    "from datasets.preprocessing import PoscarToGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed330493",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def load_model(model_name, hidden_channels=128, n_filters=64, n_interactions=3,\n",
    "               n_gaussians=50, cutoff=10, num_tasks=2, tower_h1=128,\n",
    "               tower_h2=64):\n",
    "    \"\"\"\n",
    "    load the trained ML models given the model_name.\n",
    "    It should be noted that the hyper parameters are assigned according to the specific trained hyper parameters.\n",
    "\n",
    "    args:\n",
    "        model_name: str. the name of the trained model.\n",
    "        For example: './saved_models/ms_type0_300.pt'\n",
    "    \"\"\"\n",
    "    # load the ML model.\n",
    "    setup_imports()\n",
    "    device = torch.device(device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = registry.get_model('heanet'\n",
    "                               )(hidden_channels=hidden_channels,\n",
    "                                 num_filters=n_filters,\n",
    "                                 num_interactions=n_interactions,\n",
    "                                 num_gaussians=n_gaussians,\n",
    "                                 cutoff=cutoff,\n",
    "                                 readout='add',\n",
    "                                 dipole=False, mean=None, std=None,\n",
    "                                 atomref=None, num_tasks=num_tasks,\n",
    "                                 tower_h1=tower_h1,\n",
    "                                 tower_h2=tower_h2)\n",
    "    # load parameters of trained model\n",
    "    model_state = torch.load(model_name, map_location=device)\n",
    "    model.load_state_dict(model_state)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e7744e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPrediction(object):\n",
    "    \"\"\" Assign the parameters for model and datasets.\n",
    "\n",
    "    When tasks come from Multi-target learning model, it should be a list including str, such as ['ef', 'eg'].\n",
    "    At the same time, the transforms should be like ['scaling', 'scaling']\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): The saved model name.\n",
    "        tasks (List[str], optional): What tasks to predict, which is related to the model.\n",
    "            (default: ['ef', 'eg'])\n",
    "        transforms (List[str], optional): The data will be transformed with specific transformation type. For \n",
    "            example, the 'scaling', 'log', etc.\n",
    "        hidden_channels (int, optional): number of hidden channels for the embeddings\n",
    "            (default: 128)\n",
    "        n_filters (int, optional): number of filters\n",
    "            (default: 64)\n",
    "        n_interactions (int, optional): number of interaction blocks\n",
    "            (default: 3)\n",
    "        n_gaussians (int, optional): number of gaussian bases to expand the distances\n",
    "            (default: 50)\n",
    "        cutoff (int, optional): the cutoff radius to consider passing messages\n",
    "            (default: 10)\n",
    "        load_data_func (str): The dataloader object to load the data from dataset.\n",
    "            (default: 'mp')\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, tasks=None, transforms=None,\n",
    "                 hidden_channels=128, n_filters=64, n_interactions=3,\n",
    "                 n_gaussians=50, cutoff=10, load_data_func='mp'):\n",
    "        if tasks is None:\n",
    "            tasks = ['ef', 'eg']\n",
    "        self.model_name = model_name\n",
    "        self.tasks = tasks\n",
    "        self.transforms = transforms\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.n_filters=n_filters\n",
    "        self.n_interactions=n_interactions\n",
    "        self.n_gaussians = n_gaussians\n",
    "        self.cutoff=cutoff\n",
    "        if load_data_func=='mp':\n",
    "            self.train_loader, self.validate_loader, self.test_loader = load_mp_data(task=self.tasks, is_validate=True)\n",
    "        else:\n",
    "            self.train_loader, self.validate_loader, self.test_loader = load_hea_data_single_file(split_type=2, is_validate=True)\n",
    "        self.model = self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        model = load_model(self.model_name, hidden_channels=self.hidden_channels,\n",
    "                   n_filters=self.n_filters, n_interactions=self.n_interactions,\n",
    "                   n_gaussians=self.n_gaussians, cutoff=self.cutoff)\n",
    "        return model\n",
    "\n",
    "    def obtain_predictions_from_mtl(self):\n",
    "        model=self.model\n",
    "        out_pred, out_true = validate_model(model, self.test_loader, tasks=self.tasks,\n",
    "                                            transforms=self.transforms)\n",
    "        score = evaluate(out_pred, out_true)\n",
    "        print('mae in the test set is {}'.format(score))\n",
    "        return out_true, out_pred\n",
    "\n",
    "    def obtain_predictions_from_stl(self, model_name, task='ef'):\n",
    "        \"\"\"\n",
    "        This function is similar to the test function. It uses the trained model to predict the data.\n",
    "        So, it needs to initialize the model at first. Then, parameters are loaded into the ML model.\n",
    "        :param\n",
    "            model_name: 'str', the ML model name, like  './saved_models_lin_256/k_mp_log_500.pt'.\n",
    "            task: 'str'. The target predictioin.\n",
    "        :return:\n",
    "            y_true: ndarray.\n",
    "            y_pred: ndarray.\n",
    "        \"\"\"\n",
    "        model = load_model(model_name)\n",
    "        model.eval()  # freeze the dropout and BN layer\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            end_time = 0\n",
    "            # for batch in train_loader:\n",
    "            for batch in self.test_loader:\n",
    "                batch.to(device)\n",
    "                out = model(batch.atomic_numbers.long(), batch.pos, batch=batch)\n",
    "                # It does not change the variable at default\n",
    "                # However, we directly compare the log-form data to compare with previous paper.\n",
    "                if task == 'k' or task == 'g':\n",
    "                    y_label = transform('log', batch.__getitem__(task), forward=True)\n",
    "                else:\n",
    "                    y_label = batch.__getitem__(task)\n",
    "                y_true.append(y_label)\n",
    "                # It should scale into the raw range due to the prediction enlarge the original data in case of scaling.\n",
    "                # However, we directly compare the log-form data to compare with previous paper.\n",
    "                if task == 'ef' or task == 'eg':\n",
    "                    out = transform('scaling', out, forward=False)\n",
    "                y_pred.append(out)\n",
    "\n",
    "        y_true = torch.cat(y_true, dim=0).detach().cpu().numpy()\n",
    "        y_pred = torch.cat(y_pred, dim=0).detach().cpu().numpy()\n",
    "\n",
    "        print(y_true.shape, y_pred.shape)\n",
    "        print(y_true, y_pred)\n",
    "        mae_s = mean_absolute_error(y_true, y_pred)\n",
    "        r2_s = r2_score(y_true, y_pred)\n",
    "        print(r2_s, mae_s)\n",
    "        return y_true, y_pred\n",
    "    \n",
    "    def convert_data(self, filename):\n",
    "        \"\"\"\n",
    "        the file name of the poscars\n",
    "        args:\n",
    "            filename: str. './HEA_Data/Binary_POSCAR_Files/POSCAR_Co3Cr_sqsfcc'\n",
    "        \"\"\"\n",
    "        pg = PoscarToGraph(radius=self.cutoff, max_neigh=200)\n",
    "        data = pg.to_graph(filename)\n",
    "        data.to(device=device)\n",
    "        return data\n",
    "\n",
    "    def predict(self, poscar):\n",
    "        \"\"\"\n",
    "        Given a structure in 'POSCAR' format, it will predict its properties according to your requirements.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        model = self.model\n",
    "        model.eval()\n",
    "        data = self.convert_data(poscar)\n",
    "        out = model(data.atomic_numbers.long(), data.pos)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df2dd0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the processed data from D:\\GitProjects\\HEA_project\\datasets\\mp\n",
      "loading dataset of ef and eg.\n",
      "loading dataset of ef and eg.\n",
      "The total data size is 69239.\n",
      "The training data is set 60000 manually for comparison\n",
      "the score of task 0 is 0.11146018654108047\n",
      "\n",
      "the score of task 1 is 0.24510204792022705\n",
      "\n",
      "mae in the test set is 0.17828111723065376\n"
     ]
    }
   ],
   "source": [
    "mp_mtl = ModelPrediction(model_name='./saved_models_mtl/mtl_2_mp_500_best.pt',\n",
    "                         tasks=['ef' ,'eg'], transforms=['scaling', 'scaling'],\n",
    "                         hidden_channels=128, n_filters=64, n_interactions=3,\n",
    "                         n_gaussians=50, cutoff=10\n",
    "                         )\n",
    "y_true, y_pred = mp_mtl.obtain_predictions_from_mtl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21d44e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_mtl = ModelPrediction(model_name='./saved_models_mtl/mtl_2_mp_ef_eg_128_64_400_best.pt',\n",
    "#                          tasks=['ef' ,'eg'], transforms=['scaling', 'scaling'],\n",
    "#                          hidden_channels=128, n_filters=64, n_interactions=3,\n",
    "#                          n_gaussians=50, cutoff=10\n",
    "#                          )\n",
    "# y_true, y_pred = mp_mtl.obtain_predictions_from_mtl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c5bbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def plot_error_count(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    plot the error count density figure.\n",
    "    :param y_true: ndarray\n",
    "    :param y_pred: ndarray\n",
    "    :return:\n",
    "        nothing\n",
    "    \"\"\"\n",
    "    bins = 30\n",
    "    save_fig = True\n",
    "    fig_path = './fig'\n",
    "    fig = plt.figure()\n",
    "    percent = np.absolute((y_true - y_pred)/y_true)\n",
    "\n",
    "    # the density is obtained from a kernel density estimatioin with Gaussian kernel\n",
    "    # it do not support for non-Gaussian kernels since version 0.11.0\n",
    "#     fg = sns.kdeplot(data=percent, x='ef [eV/atom]', y='count density [%]')\n",
    "    fg = sns.kdeplot(data=percent)\n",
    "    sns.kdeplot\n",
    "    if save_fig:\n",
    "        plt.savefig(os.path.join(fig_path, 'fig2_error.png'), format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf1dcda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_error_count(y_true[0], y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e349f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-57.4036]], device='cuda:0', grad_fn=<ScatterAddBackward0>), tensor([[-2.9470]], device='cuda:0', grad_fn=<ScatterAddBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "poscar_dir = './HEA_Data/POSCARS'\n",
    "poscar = os.path.join(poscar_dir, 'CoCr3_sqsbcc')\n",
    "out = mp_mtl.predict(poscar)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e271e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hea_mtl = ModelPrediction(model_name='./saved_models_mtl_HEA/mtl_2_ms_mb_HEA_500_b2.pt',\n",
    "                         tasks=['ms' ,'mb'], transforms=[],\n",
    "                         hidden_channels=128, n_filters=64, n_interactions=3,\n",
    "                         n_gaussians=50, cutoff=10\n",
    "                         )\n",
    "y_true, y_pred = mp_mtl.obtain_predictions_from_mtl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
